---
title: "Analysis of AirBnB Properties in Paris"
author: "Ortiz, Pedro"
date: "2022-12-02"
output:
  pdf_document: default
  html_document:
    theme:
      bootswatch: flatly
---

To begin, we'll import the required libraries for this notebook and set the theme for all ggplot graphics, ensuring a consistent visual style.

```{r Import libraries, warning=F, message=F}
require(tidyverse)
require(GGally)
require(patchwork)
require(leaflet)
require(leafpop)
require(modeest)
require(class)
require(rpart)
require(rpart.plot)
require(rmarkdown)
theme_set(theme_minimal())
```


# Data Import and Filtering

## About the dataset

The dataset chosen for analysis is Inside AirBnB data for Paris. For readers unfamiliar with AirBnB, it's a website or application that facilitates temporary accommodations through daily rentals of houses, rooms, or apartments, primarily for tourism, in various cities worldwide. Regarding the dataset, each observation represents an active property listed on this platform, with various characteristics such as subjective distinctions (reviews, comments, or descriptions), objective features (price per night, number of beds or bathrooms), locational information (neighborhood, latitude, or longitude), and host-related attributes (superhost status, host response rate, number of properties owned, or identity verification). With this dataset description in mind, we can proceed with data downloading and filtering.

## Dataset Download

We download the dataset from (http://insideairbnb.com/get-the-data) and start by examining the first few observations to understand our dataset.

It should be noted that the meaning of each column, and the possible values they could take, are detailed here (https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=1322284596). Based on the details provided by this document, the total number of observations, and the variables planned in advance to work with this dataset, we filtered the dataset.

```{r Download the original data, message=F}

#Original data
data1 <- read_csv("listings.csv")

```


```{r View original data}
paged_table(head(data1,3))

```


As observed, there are numerous columns with data that we don't consider relevant for the analysis we intend to perform, such as picture_url, listing_url, description o amenities. Hence, we'll filter the dataset accordingly.


## Data Filtering

For filtering, we select various variables and modify others to ensure they have a manageable type for R and ourselves. For instance, converting prices from characters to numeric, or splitting the bathroom variable into two separate variables indicating quantity and type of bathroom. Additionally, we remove properties with missing data to ensure a clean and consistent dataset.

```{r Data filtering, warning=F}
#First filter
data1$host_response_rate <- as.numeric(str_remove(data1$host_response_rate, "%"))  
data1$host_acceptance_rate <- as.numeric(str_remove(data1$host_acceptance_rate, "%")) 
data1$price <- as.numeric(substring(data1$price, 2)) 


#Second filter
data2 <- data1 %>% select(id, host_id, host_response_rate,host_acceptance_rate, host_is_superhost, host_has_profile_pic, host_identity_verified, neighbourhood_cleansed, latitude, longitude, room_type, accommodates, bathrooms_text, beds, price, minimum_nights, maximum_nights, has_availability, number_of_reviews, number_of_reviews_ltm, first_review, review_scores_rating, instant_bookable, reviews_per_month ) %>%  na.omit()



#Bathroom filter
data2$bathrooms_text <- str_replace(data2$bathrooms_text , "Shared half-bath", "0.5 shared bath") 
data2$bathrooms_text <-str_replace(data2$bathrooms_text , "Private half-bath", "0.5 private bath") 
data2$bathrooms_text <- str_replace(data2$bathrooms_text , "Half-bath", "0.5 bath")
data2$bathrooms_text <- str_replace(data2$bathrooms_text , "baths", "bath")
data2[c("numb_bath","type_bath")] <- str_split(data2$bathrooms_text, " ", n = 2, simplify = T)
data2$numb_bath <- as.numeric(data2$numb_bath )
data2 <- data2 %>% select(-bathrooms_text)


```

We'll also filter properties that are available for rent at the time of dataset creation (22/09/2022), and keep those properties with more than 10 total reviews and at least 5 reviews in the last year for more current and consistent data.

```{r Third filter}

# Third filter

data3 <- data2 %>%
  filter(number_of_reviews > 10 & number_of_reviews_ltm > 5, has_availability == T) %>%
  select(-has_availability)

data3 <- data3 %>% rename(acceptance_rate = host_acceptance_rate,response_rate  = host_response_rate, superhost = host_is_superhost, profile_picture = host_has_profile_pic, verified_identity = host_identity_verified, neighborhood = neighbourhood_cleansed, year_reviews = number_of_reviews_ltm, avg_review = review_scores_rating, instant = instant_bookable)
```


Now that we've completed the data filtering, let's examine how the dimensions of the dataset have changed.

```{r Dataset dimensions}
dimensions <- matrix (NA, nrow = 3, ncol = 2)
dimensions[1,] <- dim(data1)
dimensions[2,] <- dim(data2)
dimensions[3,] <- dim(data3)

colnames(dimensions) <- c("Observations", "Variables")
rownames(dimensions) <- c("Initial Data", "Midway Filtering", "Final Data")
dimensions

```

We can observe that we've reduced our dataset by more than 75% in terms of observations and selected only a third of the variables, which we consider relevant for analysis.

# Exploratory Data Analysis

To better understand our dataset, the distributions of various variables, their relationships, and how they can help generate better linear models or classifications, we'll conduct an exploratory analysis of the data, presenting this analysis through various graphics and drawing conclusions from them.

## Analyzing Variables Separately

First, let's examine how the variables are distributed concerning the total number of properties.

We'll start by visualizing dichotomous variables, i.e., those with only two factors.

```{r dichotomous variables}
data_host <- data3 %>%gather(key = "category" , value = "VoF", c(superhost,profile_picture,verified_identity,instant)) 

data_host %>% ggplot(aes(x = category, fill = VoF)) + geom_bar(position = "dodge", width=0.5) + labs(y = "N° of observacions", x = "", fill = "", title = "Dichotomous variables") + geom_text(aes(label = ..count..), stat = "count", color = "black",position = position_dodge(width = 0.5), vjust = -0.5) + scale_x_discrete(labels = c("profile_picture" = "Profile picture", "verified_identity" = "Verified identity", "superhost" = "Superhost","instant" = "Instant rental available")) + scale_fill_manual(values=c("snow4", "tan2"), labels = c("No", "Yes"))
```

We can see here that in two of them, profile picture and verified identity, most of the observations of the dataset are yes, that is, most of the properties have owners with verified profile picture and identity, while in the case of whether it is instantly rentable or whether the host is a superhost or not, we can see a greater parity, but where no wins. This is a fact to take into account, especially if we want to make a classification of these categories based on the rest of the variables, since it will be preferable to keep those that have a higher parity, so we can get more juice to the classification according to the different models.

Once the analysis of the dichotomous variables has been completed, we will move on to the study of the categorical variables, such as neighborhood or bathroom type.

```{r Neighborhood}
neighborhood_data <- as.data.frame(table(data3$neighborhood)) %>% rename(neighborhood = Var1, number = Freq)

neighborhood_data %>% ggplot(aes(x = reorder(neighborhood,number), y = number)) + geom_col(fill = "palevioletred1") + coord_flip() + geom_text(aes(label = number), vjust = 0.5, hjust = 1.5, color = "black", size = 2.5) + labs(y = "N° of observations", x = "Neighborhood", title = "Property distribution according to neighborhood")
```

In this case, we can observe a somewhat even distribution of properties according to the neighborhood where they are located. The neighborhood with the fewest properties (Palais-Bourbon), in our dataset, has approximately 25% of the observations compared to the neighborhood with the most properties (Buttes-Montmartre). This can be better appreciated by viewing the following map of Paris, where properties are colored according to the neighborhood.

```{r Map- Spacial variables}
colors <- c('forestgreen', 'cornflowerblue', 'magenta', 'darkolivegreen4', 'indianred1', 'tan4', 'darkblue', 
                'mediumorchid1','firebrick4',  'yellowgreen', 'lightsalmon', 'tan3','darkgray', 'wheat4', '#DDAD4B', 'chartreuse', 
                'cadetblue1',"darkolivegreen1", "#7CE3D8","gainsboro")
pal <- colorFactor(palette = colors, domain = data3$neighborhood)
leaflet(data3) %>% addProviderTiles(provider = providers$CartoDB.Positron) %>% addCircleMarkers(lng = data3$longitude, lat = data3$latitude, radius = 8
                                 ,stroke = FALSE,fillOpacity = 0.5, 
                                 fillColor =  ~pal(neighborhood) ,          
                                 popup = ~leafpop::popupTable(data3,
                                       zcol = c("price", "avg_review", "accommodates"),
                                       row.numbers = FALSE, feature.id = FALSE)) %>%   addLegend(position = "bottomright", pal = pal, values = ~neighborhood, opacity = 1)
```


Continuing with the analysis of categorical variables, we will now observe how properties are distributed according to the type of room advertised.

```{r Room type}
data3 %>% ggplot(aes(x = room_type, fill = room_type)) + geom_bar() + scale_x_discrete(labels = c("Entire home/apt" = "", "Hotel room" = "", "Private room" = "", "Shared room" = "")) + labs(x = "Room type ", y = "N° of observations", fill = "", title = "Property distribution according to room type") + scale_fill_hue(labels = c("Apartament", "Hotel", "Private", "Shared")) + geom_text(aes(label = ..count..), stat = "count", vjust = -0.5, hjust = 0.5, color = "black")

```

Here it can be clearly observed that the vast majority of Airbnb properties are apartments, while there are slightly fewer than 2000 listed as private rooms, and even fewer hotels or shared rooms, with less than 200 and 100 respectively. This aligns with the purpose of the app, where people seek accommodations for vacationing or tourism, and prefer private spaces for rest and leisure over shared ones. On the other hand, it is expected that hotels do not advertise all their rooms here, as they offer a wide variety, and it may not be advantageous for them to have customers view their different types of rooms separately.

Now we will see the distribution of properties according to the maximum number of occupants proposed by their host or owner:

```{r accommodates}
#Histograma de ocupantes

data3 %>% ggplot(aes(x = accommodates), xaxp = c(1,15,15)) + geom_bar(fill = "palevioletred1") + labs(y = "Quantity", title = "Accommodates distribution", x = "Ocupants") + geom_text(aes(label = ..count..), stat = "count", vjust = -0.5, hjust = 0.5, color = "black") + scale_x_continuous(breaks = seq(1:16))
```

Clearly, there is a trend where the majority of properties accommodate between 1 and 4 occupants, while there appears to be a second "peak" at 6 occupants. This is consistent with reality, where the vast majority of people plan vacations with their families, usually comprising 6 or fewer members. Conversely, vacations with more than 9 or 10 companions are less common, resulting in fewer properties with such maximum capacity.

To conclude the exploratory analysis of the variables separately, we will examine those that are continuous, such as the price of the property or the average of the reviews given by the people who rented those properties:

```{r Continuous data, include=F}
continuous_data <- data3 %>% select(price, accommodates,number_of_reviews, avg_review, numb_bath,beds, superhost) %>% filter(numb_bath < 50) %>% rename(Price = price, Accommodates = accommodates, Number_of_reviews = number_of_reviews, Calification = avg_review, Numb_baños = numb_bath, Beds = beds) %>% mutate(superhost = str_replace(superhost, 'FALSE', 'Host'), superhost = str_replace(superhost, 'TRUE', 'Superhost')) 
```

```{r Prices}

avg_price <- mean(continuous_data$Price)
quantile_price <- quantile(continuous_data$Price, c(0.25,0.5,0.75), type = 6)

g1 <- continuous_data %>% ggplot(aes(x = Price)) + geom_histogram(binwidth=10, aes(fill=..count..), col='black') + labs(x = "Price (€)", y = "Amount", fill = "Amount") + geom_vline(xintercept = avg_price, col = "orangered1", lwd = 1.3) + geom_text(aes(x = 220, y = 750, label = as.character(round(avg_price,2))),stat = "unique", size = 4)

g2 <- continuous_data %>% ggplot(aes(x = Price)) + geom_boxplot(fill = "burlywood1") + labs(x = "Price (€)", y = "") + geom_text(aes(x = 82, y = 0.5, label = "82"),stat = "unique", size = 2.5) + geom_text(aes(x = 120, y = 0.5, label = "120"),stat = "unique", size = 2.5) + geom_text(aes(x = 200, y = 0.5, label = "200"),stat = "unique", size = 2.5) + theme(axis.text.y=element_blank(), axis.ticks.y=element_blank())

g1 + g2 + plot_layout(nrow = 2, heights = c(2, 1))
```

In this graph, we can observe the distribution of property prices present here. It's clear that the vast majority of properties have a price below €200 per night, and half of the properties have a price lower than or equal to €120 per night. However, we see that the average is higher than this number, standing at €165.33 per night, because properties with extremely high prices per night contribute to raising the average, making it a less robust metric.

Finally, we will analyze the ratings given by users to the properties.


```{r Califications}
avg_calification <- mean(continuous_data$Calification)
continuous_data %>% ggplot(aes(x = Calification)) + geom_histogram(binwidth=0.05, aes(fill=..count..), col='black') + labs(x = "Calification", y = "Amount", fill = "Amount", title = "Property distribution according to calification") + geom_vline(xintercept = avg_calification, col = "orangered1", lwd = 1.1) + geom_text(aes(x = 4.815, y = 1750, label = as.character(round(avg_calification,2))),stat = "unique", size = 4) + scale_fill_gradient(low='#FF3E96', high='slateblue3')
```

It's clear that almost all observations have an average review rating higher than 4 out of 5 stars. This leads us to consider various possibilities for this trend. Could it be that all properties are extremely good? Perhaps the users of Airbnb tend to be very lenient with their ratings. Additionally, it's worth considering whether the filtering criteria influenced this distribution. Properties were selected based on having more than 10 total reviews and more than 5 reviews in the last year. This filtering criterion may have impacted the distribution of review ratings observed in the dataset.


Regarding the first two questions, with the data available in the dataset and the analysis conducted (without natural language processing), it's not possible to answer them definitively. However, the third question does have an answer, and it is yes, the criterion used did influence the results. This is because there are properties with very few and poor ratings, which creates a negative feedback loop. Users don't choose these properties because of their low ratings, preventing them from accumulating more reviews or improving their average rating. As a result, they are ultimately excluded from the analysis.

## Relationship between variables

At this moment we are looking for correlations between the variables in the dataset. Mainly, we are seeking relationships between price and other dataset variables, but we are also adding all relationships between the other variables themselves, as this could be an interesting piece of information to consider when modeling or classifying (with this purpose, points are also separated into two colors depending on whether they are a superhost or simply a host, which will be very useful later in the work).

To start, we will work with already selected variables (price, occupancy, number of reviews, average review score, number of bathrooms, beds, and superhost), as these are the ones we anticipate will be most influential when building different models, or they have some relationship with each other.

We will see a "super graph", separating, as mentioned, into host or superhost, from which we will extract those that are most interesting to draw conclusions.

```{r relationship graphic, message=F}
g3 <- continuous_data %>% select(-superhost) %>%  ggpairs(aes(color = continuous_data$superhost, alpha = 0.5), upper = list(continuous = wrap("cor", size = 2.5))) + theme_bw()
g3
```

The first graph we'll see will be the one of the rating, based on whether the owner is a host or a superhost.

```{r Califications - host vs superhost}


continuous_data %>% filter(Calification > 3.5) %>% ggplot(aes(x = Calification)) + geom_density(aes(fill = superhost) , lwd = 0.5, alpha = 0.5) + labs(x = "Calification", y = "Density", fill = "", title = "Calification distribution according host type") + scale_fill_hue(labels = c("Host", "Superhost"))  + geom_vline(xintercept = median(continuous_data$Calification), lwd = 1.2) + geom_text(aes(x = 4.84, y = 4, label = "4.78"),stat = "unique", size = 4)
```

Here we can again notice how the ratings are extremely positive, both for hosts and superhosts. However, it can also be seen that within this extreme positivity, there's even a higher rating for those properties with a superhost as the owner, as evidenced by the peak of the superhost, higher than the median of the averages (4.78), while that of the hosts is "only" higher than 4.5 but lower than 4.78.

From the "supergraph" seen earlier, we can also extract for individual analysis the one of occupants based on the property's price, but we do it divided into two graphs, one for those hosted by superhosts and the other for those hosted by regular hosts.

```{r Accommodates vs price}
g4 <- continuous_data %>% filter(superhost == "Superhost") %>%  ggplot(aes(x = Price, y = Accommodates))  + labs(x = "Price (€)", y = "Accommodates", title = "Only superhost") + geom_jitter(col = "#FFA500", alpha = 0.5)
g5 <- continuous_data %>% filter(superhost == "Host") %>%   ggplot(aes(x = Price, y = Accommodates))  + labs(x = "Price (€)", y = "Ocupants", title = "Only host") + geom_jitter(col = "#FFA500", alpha = 0.5)
g4 + g5
```

A similar pattern can be observed in both, with the only difference being that there are more regular hosts than superhosts, resulting in a greater number of properties for less than 7 occupants and less than 350 euros per night. In both cases, we see that the price seems to increase as the number of occupants increases, but this growth doesn't appear to be as pronounced as one might expect.

Now we'll move on to relate occupants with beds, where initially, one might think they are closely related, as are the relationships between occupants and beds, and between the number of bathrooms and beds.

```{r Accommodates vs beds}

continuous_data %>% ggplot(aes(x= Accommodates, y= Beds) ) + geom_jitter(col = "#FFA500", alpha = 0.5)
```

Clearly, a relationship of dependency between occupants and beds can be observed, as one increases, so does the other, which makes sense. It's worth noting that this relationship is not usually one-to-one because there are beds of more than one place, or different sofa beds, which can alter the one-to-one relationship between beds and occupants.


```{r Numbs baths vs beds}
continuous_data %>% filter(Numb_baños < 50) %>% ggplot(aes(x = Numb_baños, y = Beds)) + geom_jitter(col = "#FFA500", alpha = 0.5) + scale_x_continuous(breaks = seq(0, 8, 0.5)) + xlab("Number of bathrooms")
```

Here we see that the relationship one might expect, where more beds equate to more bathrooms, does not hold true. The majority of properties have between 1 and 2 bathrooms regardless of the number of beds. It's also noteworthy that as the number of bathrooms in the property increases, there are more beds as a lower limit, but the upper limit does not increase in relation to those with 1 or 2 bathrooms.

It's important to highlight that in these last three presented graphs, exact points were not used, as it wouldn't show the quantity well. Instead, the geom_jitter function was used, which adds some noise to the points, allowing us to distinguish those with the same coordinates.

Finally, we will observe the relationship of our temporal and spatial variables with the price of the property to rent, starting with the temporal variable (date of the first review).


```{r First review graphic}
data3 %>% ggplot(aes(x = first_review, y = price)) + geom_point(col = "#FF82AB",alpha = 0.5)  + labs(title = "Date of first review and price",x = "Date of first review", y = "Price (€)") + scale_x_date(date_breaks = "1 year",date_labels = "%Y") 
```

We can observe that once the number of first reviews stabilizes over time, there is no noticeable increase in property prices. However, prior to this stabilization, there is an upward trend. Therefore, when considering a possible price prediction, the temporal variable may not contribute significantly. An additional point to note is the COVID-19 pandemic and the total lockdown in March and April 2020, evident in this graph as the only noticeable gap over time, in early 2020.

To conclude our analysis of the relationships between variables, we will examine how the spatial variable, in this case viewed from latitude and longitude, interacts with the price. However, for this specific case, we standardized it by taking the price per occupant of the properties and divided it into cheap or expensive, depending on whether it is below or above the median for each specific observation. Taking the median generates a division of 50% of the dataset into cheap and 50% into expensive, unlike what would have happened if we had taken the average.


```{r Cheap vs Expensive - Map}

data_price <- data3 %>% mutate(price_per_person = price/accommodates) %>% select(latitude,longitude,price,price_per_person)
med_price_per_person<- median(data_price$price_per_person)

data_price <- data_price %>% mutate(price_category = case_when(price_per_person > med_price_per_person ~ "expensive",  price_per_person <= med_price_per_person ~ "cheap"))

price_colors <- c("brown3","steelblue")
pal_price <- colorFactor(palette = price_colors, domain = data_price$price_category)
leaflet(data_price) %>% addProviderTiles(provider = providers$CartoDB.Positron) %>% addCircleMarkers(lng = data_price$longitude, lat = data_price$latitude, radius = 8
                                 ,stroke = FALSE,fillOpacity = 0.5, 
                                 fillColor =  ~pal_price(price_category)) %>%   addLegend(position = "topright", pal = pal_price, values = ~price_category, opacity = 1)
```

It's clear that properties classified as expensive according to our criteria are clustered in the center of Paris, while those classified as cheap are mostly located in the periphery. There are exceptions to this, of course, but overall, it's evident that the location of properties influences their price, at least when considering the price per occupant. We'll take this into account and consider it carefully when modeling the price of a property.

# Linear Modeling and Fitting

Below, we'll attempt to perform linear fitting on the data we have to predict the price of each place for lodging. Before we begin, we'll outline a series of hypotheses about the data that we'll try to verify or refute.
Firstly, it may make sense to predict the price based on different types of variables.

-For example, we can explore a relationship with user reviews to see if this influences the price.

-On the other hand, we can separate the fittings according to data about the establishment itself and its location to see how each one influences the price.

-Lastly, it might be interesting to find out if combining the best variables to predict the price for each of these fittings can lead to a single fitting that is better than all the others.

-Following this logic, it seems reasonable to think that a property that allows lodging for a single night may have a higher price than a property that only allows lodging for a minimum of one week, and perhaps for this reason, there is an important correlation between the price and the minimum number of nights for lodging. Let's see if this is indeed the case.


```{r Fittings}

Price<-data3$price 
own_model<-lm(Price ~ data3$minimum_nights + data3$accommodates + data3$beds + data3$type_bath + data3$numb_bath)

ajuste_reviews<-lm(Price ~ data3$avg_review + data3$reviews_per_month + data3$first_review + data3$number_of_reviews)


ajuste_ubicacion<-lm(Price~data3$latitude + data3$longitude + data3$neighborhood)

```

We're looking for the best of each one. To do this, we need a way to measure the error.

```{r Functions}

MAPE_<-function(y, p){
  return (mean(abs(y-p))/mean(y))
}

accuracy_<-function(x , y){
  return( (sum(x==y)/length(y)) * 100 )
}

percentage_error <-function(x,y){
  return(100 - accuracy_(x,y))
}

crossval<- function(data, ys, model_x, n_obs=round(0.2*nrow(data)) , fun_error=MAPE_ , n_samples=10){
  n<-nrow(data)
  errors<-c(1:n_samples)
  for (i in 1:n_samples)
  {
    to_fit<-sample(c(1:nrow(data)), nrow(data)-n_obs, replace = F) 
    fit.cv<- lm(as.formula(paste( "price ~", model_x, sep='')),data=data[to_fit,]) #Generate the fitting
    predicts.oos<-predict(fit.cv,newdata=data) # Predict price   
    # Error function
    errors[i]<-fun_error(ys[-to_fit], predicts.oos[-to_fit])
  }
  
  return(mean(errors))
}

vector_to_color <- function(aux,MAPE){
  for (i in 1:length(aux)) {
    if (aux[i] > MAPE){
      aux[i] <- "brown3"
    } else {
      aux[i] <- "steelblue"
    }
  }
  return(aux)
}


```
 
## Modeling according to property-specific variables

Now we'll use these functions to determine which is the best fit among the property-specific variables.

```{r property-specific variables}

property_specific_variables<-c( "accommodates",  "minimum_nights", "numb_bath" , "beds", "accommodates + numb_bath","type_bath + beds", "numb_bath + beds", "accommodates + beds", "type_bath + accommodates", "minimum_nights + accommodates", "minimum_nights + numb_bath", "minimum_nights + beds", "minimum_nights + type_bath",  "minimum_nights + accommodates + numb_bath", " minimum_nights + type_bath + beds", "minimum_nights + accommodates + type_bath", "minimum_nights + beds + numb_bath","minimum_nights + accommodates + numb_bath + type_bath + beds", "type_bath + accommodates + beds", "type_bath + accommodates + numb_bath"   )

aux<-1:length(property_specific_variables)

for (i in 1:length(property_specific_variables)) {
  aux[i]<-crossval(data3,Price, property_specific_variables[i])
}

property_specific_variables[which.max(aux)]

```

With this experiment, it seems we can already refute one of the hypotheses proposed (at least for this dataset). The highest error in predicting the price is using the variable of minimum number of nights to stay. This may seem nonsensical at first, but with a bit more information about how the app works, it can be seen that it already offers certain discounts for staying more than a certain number of days. In other words, if there is indeed a benefit to staying longer, this information is not reflected in this dataset; it's something that the app internally manages between those offering accommodation and those staying.

```{r property-specific errors, warning=F}

property_specific_colors <- vector_to_color(aux,0.45)
data_frame(property_specific_variables,aux) %>%  ggplot(mapping = aes(x = reorder(property_specific_variables,aux), y = aux)) + geom_col( fill=property_specific_colors) + labs(x = "Variables", y = "MAPE", title = "MAPE according to property-specific variables" ) + scale_x_discrete(labels = function(x) str_wrap(x, width = 50)) + coord_flip() + geom_text(aes(label = round(aux,3)), nudge_y = - 0.05, col = "white")
```

This graph shows that when the variable "occupants" is used, the error in the fit decreases notably. This suggests that there is a correlation that can be linearly approximated between the price and this variable. There also appears to be another, albeit smaller, jump when the variable "beds" is used, which makes sense if we observe that there is a very close relationship between the "beds" and "occupants" variables, as mentioned in the dataset exploration. On the other hand, variables like "bathrooms" contribute to reducing the MAPE (Prediction Mean Absolute Error) but in a very insignificant way and often depends on the random set chosen for cross-validation.

## Modeling according to subjective variables

Next, we'll examine the different linear fits generated for the price according to the various subjective variables present in the dataset, such as the average of reviews or the quantity of reviews.


```{r subjective variables}
subjective_variables<-c(  "avg_review", "reviews_per_month", "first_review" ,"number_of_reviews",  " avg_review +  reviews_per_month +  first_review + number_of_reviews","avg_review + number_of_reviews", " first_review + number_of_reviews", "avg_review +  reviews_per_month ", "first_review + avg_review", "reviews_per_month + number_of_reviews", "avg_review +  reviews_per_month +  first_review", "avg_review +  reviews_per_month + number_of_reviews","avg_review + first_review  + number_of_reviews" )

aux<-1:length(subjective_variables )

for (i in 1:length(subjective_variables )) {
  aux[i]<-crossval(data3,Price, subjective_variables [i])
}


data_frame(subjective_variables,aux) %>% ggplot(mapping = aes(x = reorder(subjective_variables,aux), y = aux)) + geom_col( fill="brown3") + labs(x = "Variables", y = "MAPE", title = "MAPE according to subjective variables" ) + scale_x_discrete(labels = function(x) str_wrap(x, width = 50)) + coord_flip() + geom_text(aes(label = round(aux,3)), nudge_y = - 0.05, col = "white")

```

In this case, none of the fits seem to be good enough as they all have a MAPE greater than 0.55. This would refute another of our hypotheses because only with this type of data can we predict the price of accommodations reliably. However, by comparison, it is shown that the type of data used earlier regarding the characteristics specific to the lodging has a better correlation with its price.

This could be due to a myriad of reasons, but it is worth noting that if you observe the exploratory data graph where the distribution of the rating (average of reviews) is seen, you can clearly see that the median is at 4.78 and there are practically no data points with an average rating lower than 4. This shows that if there is indeed a subjective preference to increase the price based on a higher average rating, this dataset would never know because it lacks data on poor ratings. That is to say, it considers the worst type of rating to be something close to 4, which for the vast majority is a very good rating. This does not necessarily mean that there is indeed a relationship between reviews and price; it only means that in this dataset, it is not possible to find it even if it exists.


## Modeling based on location variables

Finally, we do the same for the locational variables, namely, neighborhood, latitude, and longitude.

```{r locational variables}
locational_variables<-c( "latitude" , "longitude",  "neighborhood", " latitude +longitude ", "neighborhood + latitude" , "neighborhood + longitude" ,  " latitude +longitude + neighborhood"  )

aux<-1:length(locational_variables )

for (i in 1:length(locational_variables )) {
  aux[i]<-crossval(data3,Price, locational_variables [i])
}




locational_colors <- vector_to_color(aux,0.51)
data_frame(locational_variables,aux) %>% ggplot(mapping = aes(x = reorder(locational_variables,aux), y = aux)) + geom_col( fill=locational_colors) + labs(x = "Variables", y = "MAPE", title = "MAPE according to locational variables" ) + scale_x_discrete(labels = function(x) str_wrap(x, width = 25)) + coord_flip() + geom_text(aes(label = round(aux,3)), nudge_y = - 0.05, col = "white")
```

In this graph, the MAPEs of the fits are shown, and a blue line separates the fits that do not use the neighborhood variable from those that do. Again, a significant jump in MAPE can be observed, indicating that the neighborhood is the one most related to the price among these variables. However, latitude and longitude, two variables that literally define the neighborhood, seem to have a poor fit for the price. Why could this be?

If we recall the map graph dividing the "cheap" and "expensive" accommodations, we can remember that it resembled a level surface of an elliptical paraboloid (accommodations in the geographical center of the city seemed more expensive, while those around appeared cheaper). This means that for a linear fit (a sort of hyperplane in the space of the analyzed variables), it is very difficult to approximate latitude and longitude to the price. On the other hand, since the neighborhood is categorical, it represents a more limited section of latitude and longitude where it is easier to determine whether a cheap or expensive price predominates in that environment (it presents similarities to a classification task with nearest neighbors).

Then, adjustments were made using the poly() function to give 2 and up to 3 degrees of freedom to the latitude and longitude variables. However, although this significantly reduces the MAPE, it does not perform as well as the neighborhood variable. After this, adding degrees of freedom to the variables to fit them better seemed forced and unproductive, so the idea was abandoned.


## Modeling with the Best Variables Found in the Previous Three Sections

Finally, an attempt will be made to use the best variables of each type together to predict the price as accurately as possible based on the data we have.



```{r all variants}
all_variables<-c("type_bath + accommodates + neighborhood + avg_review ", "type_bath + accommodates + neighborhood", "minimum_nights + type_bath + accommodates + neighborhood + avg_review", "accommodates + neighborhood","minimum_nights + accommodates + numb_bath + type_bath + beds + neighborhood + avg_review", "latitude + longitude + beds + numb_bath + minimum_nights" )

aux_all<-1:length(all_variables )

for (i in 1:length(all_variables )) {
  aux_all[i]<-crossval(data3,Price, all_variables [i])
}

all_colors <- vector_to_color(aux_all,0.42)
data_frame(all_variables,aux_all) %>%  ggplot(mapping = aes(x = reorder(all_variables,aux_all), y = aux_all)) + geom_col( fill=all_colors) + labs(x = "Variables", y = "MAPE", title = "MAPE according to selected variables" ) + scale_x_discrete(labels = function(x) str_wrap(x, width = 25)) + coord_flip() + geom_text(aes(label = round(aux_all,3)), nudge_y = - 0.05, col = "white")

```

## Analysis of the Best Model Obtained

Once the best model considering different variables has been obtained, and taking it according to the lowest mean squared error, we will proceed to analyze it.

```{r best model}
best_fit_variant <- all_variables[which.min(aux_all)]
best_fit <- lm(as.formula(paste( "price ~", best_fit_variant, sep='')),data=data3)
predicts <- predict(best_fit,data3)
fit_line <- lm(predicts~Price)
data_frame(predicts,Price) %>% ggplot(aes(x = Price, y = predicts)) + geom_point(alpha = 0.7) + geom_smooth(method = "lm",formula = y~x,col = "red") + geom_abline(slope = 1, intercept = 0, colour = "green", size = 1) + labs(x = "Real price", y = "Predicted price", title = "Best fit price vs real price")
```

In this graph, we can observe the distribution of observations according to their actual price and the price predicted by the model. The red line indicates the fit of the predicted price based on the actual price, meaning it's the line that best represents the distribution of points observed in the graph. As for the green line, it represents the identity line, where the predicted price equals the actual price, which would be considered an ideal fit to our data. As we can see, they clearly do not coincide, as we analytically saw earlier, since we have an average error of approximately 38%.

```{r errors best model}
error_data <- data_frame(data3$price,best_fit$residuals)


error_data <- error_data %>% rename(price = `data3$price`, errors = `best_fit$residuals` ) %>%  mutate(graph_color = ifelse(errors > -450,"steelblue","brown3"))


error_data %>% ggplot(aes(x = price, y = errors, color = graph_color)) + geom_point(alpha = 0.7) + labs(x = "Real price", y = "Errors", title = " Model errors according to the real price", color = "" ) +
  scale_color_manual(labels = c("Outlier","Typical data"), values = c("brown3","steelblue"))
```

This graph displays the errors of our model relative to the actual price, which is similar to the graph seen earlier, although in this case, we differentiate by color, making it easier to identify 5 outliers. 
Here, we observe 5 outliers that seem to be affecting this model, causing its efficiency to decrease. What could these observations have in common?



```{r outliers}
paged_table(data3[c(1979,3472,13421,13494,13419),] %>% select(accommodates,price))


```

We can observe that all of them have 16 occupants, and 4 out of the 5 have a relatively low price for the number of people that can be accommodated in those properties. Therefore, we will proceed to redo this adjustment to see how the MAPE varies, but this time without taking into account those observations.

```{r best model without outlier}
data3_no_out <- data3[-c(1979,3472,13421,13494,13419),]
best_fit_no_out <- lm(as.formula(paste( "price ~", best_fit_variant, sep='')),data=data3_no_out)

adjusted_data <- data_frame(a = c(crossval(data3_no_out,data3_no_out$price,best_fit_variant),min(aux_all)), b = c("Without outliers", "With outliers"))
adjusted_data %>% ggplot(mapping = aes(x = reorder(b,a), y = a))+ geom_col(fill = "steelblue") + labs(x = "", y = "MAPE", title = "MAPE according to outlier contention" ) + coord_flip() + geom_text(aes(label = round(a,5)), nudge_y = - 0.05, col = "white")

```

We can observe that considering the 5 data points seen as outliers practically does not change the error that the best-fitting model will have, contrary to what one might have thought previously. The error only decreases by `r abs(round(adjusted_data[1,1]-adjusted_data[2,1],4))*100`%.

# Classification


We will proceed to classify the type of host (superhost or host). We noticed from the correlation plot that there seems to be a practically clear delineation regarding this variable when it is plotted against the price and the average of the reviews. We will make a slight change and instead of using price, we will use price_per_person simply by intuition. Initially, we will see with the plot if the classification model makes sense or not.

To begin, we will change the dataset by adding the columns of price per person (that is, the price per night in the property divided by the number of occupants), and change the superhost variable to false or true.

```{r classification}

classification_data <- data3 %>% mutate(first_review= as.numeric(first_review))

classification_data <- data3 %>% mutate(price_per_person = price / accommodates )


classification_data <- classification_data %>% mutate (superhost = case_when(superhost == FALSE ~ "Host",  superhost == TRUE ~ "Superhost"))

```

Then we will see the plot relating the aforementioned variables to begin to understand how they relate to the objective of classification.


```{r plot classification ,warning=F, message=F}
d <- classification_data %>% select(avg_review, price_per_person, superhost)
d %>% ggplot(mapping = aes(x = price_per_person, y = avg_review, color = superhost )) + labs(x = "Price per person", y = "Average of reviews", color = "") +  geom_point() + geom_abline(slope = 1/914, intercept = 4.57 , size = 1) + geom_abline(slope = 0, intercept = 4.8, col = "green", size = 1) +xlim(0,300) + ylim(3.5,5)



```

Indeed, there are two clusters of points that, although they intersect and are very narrow, it is possible to attempt to plot one or two separating lines (shown in the graph in black or green, depending on how marked their slope is) that approximately divide them effectively.

## K-Nearest Neighbors Classification Model

Next, we attempt to use the classification method using k-nearest neighbors using these two variables.

```{r knn}

train<-classification_data %>% 
  select(price_per_person, avg_review, superhost)



#  split the dataset in train and test

N   <- nrow(train)
p   <- 0.8
ind <- sample(1:N, round(p*N), replace = F)

d.train <-train[ind,] %>% select(-superhost)
d.test  <- train[-ind,] %>% select(-superhost)

d.train_superhost <- train[ind,3] 
d.test_superhost  <- train[-ind,3] 

ks<-seq(5,49,2)
acu<-1:length(ks)


for (i in 1:length(ks)) {
  pr <- knn(d.train,d.test, d.train_superhost$superhost ,k=ks[i])
  acu[i]<-accuracy_(pr, d.test_superhost$superhost )
}

optim_k <- 4 + which.max(acu)*2-1

data_2 <- data_frame(ks = ks, acu = acu)
data_2 %>% ggplot(aes(x = ks, y = acu)) + geom_point() + theme_minimal() + scale_x_continuous(breaks = seq(5,49,2)) + labs(x = "Number of neighbours", y = "Accuracy")

```


It seems that with the optimal k (`r optim_k`) using these two variables, we can achieve an approximate accuracy of 70% (`r max(acu)`), which initially seems to be a good classification model. To study this in greater depth, we will compare this with another classification, this time given by decision trees.

## Decision Tree Classification Model

However, using the same two variables for classification with trees, we discover something quite interesting.


```{r decision tree}
#  Split the dataset in train and test
N   <- nrow(d)
p   <- 0.8
ind <- sample(1:N, round(p*N), replace = F)

d.train <- d[ind,]
d.test  <- d[-ind,]

# classification tree

fit0 <- rpart(superhost ~ price_per_person + avg_review, data = d.train, method = 'class')

rpart.plot(fit0)
```


```{r classification map}


d.plot <- expand_grid(price_per_person = seq(0,250,10) , avg_review = seq(3.5, 5,0.1) ) %>% 
  mutate(superhost = predict(fit0, newdata = ., type = "class"))

ggplot(data = d.plot, aes(x = price_per_person, y = avg_review, fill = superhost, color = superhost)) + 
  geom_tile() + 
  geom_point(data = d.test) +
  theme_classic()
```


```{r Confusion matrix}
d.test$superhost.pred.0 <- predict(fit0, newdata = d.test, type = "class")

conf.mat.0 <- table(d.test$superhost.pred.0, d.test$superhost)

acc <- 100 * sum(diag(conf.mat.0)) / sum(conf.mat.0)

conf.mat.0

```

The accuracy of this last model is `r round(acc,2)`.

First of all, it can be observed already in the decision tree that the variable price_per_person is never used for classification. Additionally, in the classification map, it can be seen that the only division is a line near the average of 4.8 reviews, which divides the clusters of points into two. This seems to be saying that the price does not affect the classification used by the model at all.
In fact, another graph is shown below, this time of the average of reviews as a function of the first review date, and the division is very similar.

The same was found for many other variables that are not worth showing, but in none of them was a clear separating line found that was not a line parallel to the x-axis that cuts the axis of the average reviews at 4.8.


```{r first review vs average ,warning=F}

d <- classification_data %>% select(avg_review, first_review, superhost)
d %>% ggplot(mapping = aes(x = first_review, y = avg_review, color = superhost )) + labs(x = "First review date", y = "Average of reviews", color ="") +  geom_point() + geom_abline(slope = 0, intercept = 4.8,size = 1) + ylim(3.5,5)

```

Finally, a classification is shown using decision trees only based on the average of the reviews, separating hosts from superhosts. This means that the decision tree only distinguishes based on the average of the reviews and never with respect to the other variable. For this tree, it is shown that the error is similar, confirming our assumption about the relationship between the price or the price per person and the fact of being a Superhost or not.


```{r new decision tree}
train<-classification_data %>% 
  select(avg_review, superhost)

N   <- nrow(d)
p   <- 0.8
ind <- sample(1:N, round(p*N), replace = F)

d.train <- d[ind,]
d.test  <- d[-ind,]


fit0 <- rpart(superhost ~ avg_review, data = d.train, method = 'class')

rpart.plot(fit0)

d.test$superhost.pred.0 <- predict(fit0, newdata = d.test, type = "class")

conf.mat.0 <- table(d.test$superhost.pred.0, d.test$superhost)

acc <- 100 * sum(diag(conf.mat.0)) / sum(conf.mat.0)


```

The accuracy of this last model is `r round(acc,2)`.

## Conclusions drawn from the classification

It is worth mentioning that intrigued by curiosity, we indeed looked into how the app determined whether a host was a superhost or not, and we found something quite striking.

We found that a superhost was determined by 4 conditions:

*Having a response rate greater than 90% in the last 24 hours.
*Having a cancellation rate lower than 1%.
*Having more than 100 nights distributed across at least 3 completed stays.
*Having an average of the reviews over the last year greater than 4.8.

Indeed, this last condition is what is being found in the classification adjustment. However, it is important to note that in the case of our dataset, we do not have an average of reviews over the last year but rather an overall average of the reviews. This could mean that if we have a 70% effective accuracy using only the overall average, then approximately 70% of the hosts remained in the same division of the average of reviews since 2010 (i.e., below 4.8 or above 4.8).

On the other hand, it was also found that despite having data in the dataset related to the response rate and cancellation rate, the graphs show the same as the graph of the first review date along with the average of the reviews. They simply do not seem to be as deterministic about how a superhost is selected (unlike the average of reviews). Again, for each answer, a new question arises, and it may be that while it is necessary to have a response rate greater than 90% in the last 24 hours, perhaps this is not something that the app actually checks every 24 hours but once a month, for example. Or something entirely different that seems to make more sense is that both the response rate and the cancellation rate do not hold up over time as well as the average of the reviews does. But to try to test these hypotheses, more data distributed over time would be needed, and this is a variable that we do not have (we only have the date of the first review).

# Final Conclusions

As a final conclusion, it can be said that the initial questions were answered to a certain extent, and interesting relationships were found in the variables of the dataset. For example, linear classification models found close relationships between some of the variables and the price of accommodations, and then with further analysis, relationships were found with the fact of being a superhost or not in the Airbnb app.

On the other hand, it must be clear that there is still quite a bit left unanswered, both because the dataset is not extensive enough and due to limited resources available throughout this work. One of the questions that remains after this analysis to pose is, for example, if relationships between reviews and the price of properties could be found with a better distribution of review averages. Consequently, why is this distribution the way it is? Are all accommodations in Paris incredibly good compared to the rest of the world? Or is Airbnb hiding information? Or perhaps users tend to only rate positively.

Furthermore, an analysis with more temporal data is also pending to determine with greater precision what was mentioned above. All of these questions remain as open questions that could not be resolved with the data present in this dataset.